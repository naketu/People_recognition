{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605c9c62",
   "metadata": {},
   "source": [
    "# People detection with YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb78c9e1-be8c-4886-ad77-d722deecde78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prerequisites:\n",
    "\n",
    "# !pip install torch\n",
    "# !pip install imutils\n",
    "# !pip install argparse\n",
    "# !pip install imutils\n",
    "# !pip install cv2\n",
    "# !pip install numpy\n",
    "# !pip install ultralytics\n",
    "# !pip install -U ultralytics sahi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfb14b",
   "metadata": {},
   "source": [
    "## Libraries import + initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f64b087-41b0-4aac-8b16-1b1c5b1af685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_prediction\n",
    "\n",
    "from sahi.predict import get_sliced_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6013f05",
   "metadata": {},
   "source": [
    "## Path to the video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5edc5b8-9957-42d1-8bf3-dad12378c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video = r\"C:\\Users\\aksen\\OneDrive\\Desktop\\people detection video\\crowd.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609bfc9",
   "metadata": {},
   "source": [
    "## Downloading weigths for the detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcabfde5-c4c1-457b-8394-76e34efa2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model_path=\"yolov8m.pt\",\n",
    "    confidence_threshold=0.3,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8ead2",
   "metadata": {},
   "source": [
    "## Reading frames from the video and run the model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb06880-5a90-479d-a2ee-03abed7df13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(path_to_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4053cc5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# video recording\n",
    "recording = cv2.VideoWriter(filename=r\"C:\\Users\\aksen\\OneDrive\\Desktop\\people detection video\\detected_video.mp4\",\n",
    "    fourcc=-1,\n",
    "    fps=15,\n",
    "    frameSize=(1920, 1080)\n",
    ")\n",
    "\n",
    "\n",
    "# iterating over the video frames\n",
    "\n",
    "flag, frame = video.read()\n",
    "\n",
    "while flag:\n",
    "\n",
    "    \n",
    "    # detecting people\n",
    "    \n",
    "    predictions = get_sliced_prediction(\n",
    "        frame,\n",
    "        detection_model,\n",
    "        slice_height=512,\n",
    "        slice_width=512,\n",
    "        overlap_height_ratio=0.1,\n",
    "        overlap_width_ratio=0.1,\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    coco_results = predictions.to_coco_predictions()\n",
    "    \n",
    "\n",
    "    # filtering out irrelevant objects and drawing areas with detected people on the frame    \n",
    "    \n",
    "    for c in coco_results:\n",
    "        if c['category_name'] == 'person':\n",
    "            \n",
    "            xA, yA = c['bbox'][0], c['bbox'][1]\n",
    "            w, h = c['bbox'][2], c['bbox'][3]\n",
    "            \n",
    "            cv2.rectangle(frame, (int(xA), int(yA)), (int(xA+w), int(yA+h)), (0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    # Drawing the frame itself\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    recording.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    \n",
    "    # Continuing with the next frame\n",
    "    \n",
    "    flag, frame = video.read()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefda639",
   "metadata": {},
   "source": [
    "# Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121ec05",
   "metadata": {},
   "source": [
    "## Representation of the model detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://github.com/naketu/People_recognition/blob/master/crowd_detected.png?raw=true\", width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2f7ee",
   "metadata": {},
   "source": [
    "Комментарии в коде я оставлял на английском языке, чтобы не переключаться на русскую раскладку во время программирования. Надеюсь это не повлияет на результат)\n",
    "\n",
    "Модель с использованием SAHI работает гораздо лучше чем без. Однако из за дробления картинки на маленький части, модель иногда выделяет части одного человека как несколько разных. При этом модель хорошо определила как близких так и дальних людей.\n",
    "\n",
    "Можно сделать вывод что точность модели, как и ее полнота, довольно хороши. Чтобы улучшить результат нужно поработать над распознаванием людей в левом углу картинки (например добавить рамки к картинке), а также настроить размер окна работы алгоритма SAHI. Вероятно, стоит его увеличить чтобы убрать проблемы с ложным распознаванием нескольких частей человека как отдельных объектов.\n",
    "\n",
    "Для улучшения скорости работы модели стоит использовать вычисления на видеокартах вместо процессора - однако у меня внезапно полетела cuda, и перенести вычисления на видеокарту не удалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b93134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
